{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare ClinicalBERT, BERT, GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import importlib\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, log_loss, average_precision_score\n",
    "\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, log_loss, average_precision_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertForMaskedLM, BertConfig, BertModel, InputExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(choice=\"bert\"):\n",
    "    if choice == \"bert\":\n",
    "        name = \"bert-base-cased\"\n",
    "        tokenizer = transformers.BertTokenizer.from_pretrained(name)\n",
    "        config = transformers.BertConfig.from_pretrained(name)\n",
    "        lm = transformers.BertForMaskedLM(config)\n",
    "        \n",
    "    elif choice == \"gpt2\":\n",
    "        name = \"gpt2\"\n",
    "        tokenizer = transformers.GPT2Tokenizer.from_pretrained(name)\n",
    "        config = transformers.GPT2Config.from_pretrained(name)\n",
    "        lm = transformers.GPT2LMHeadModel(config)\n",
    "        \n",
    "    elif choice == \"clinicalbert\":\n",
    "        name = \"clinical bert\"\n",
    "        bert_path = '/scratch/gobi1/zining/shared_data/pretrained_bert_tf/biobert_pretrain_output_all_notes_150000/'\n",
    "        lm = BertForMaskedLM.from_pretrained(bert_path)\n",
    "        tokenizer = BertTokenizer.from_pretrained(bert_path)\n",
    "        \n",
    "    print (\"choice: {}, vocab_size: {}\".format(\n",
    "        name, tokenizer.vocab_size))\n",
    "    return tokenizer, lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choice: bert-base-cased, vocab_size: 28996\n",
      "choice: gpt2, vocab_size: 50257\n",
      "choice: clinical bert, vocab_size: 28996\n"
     ]
    }
   ],
   "source": [
    "lm_names = [\"bert\", \"gpt2\", \"clinicalbert\"]\n",
    "\n",
    "tokenizers, lms = [], []\n",
    "for name in lm_names:\n",
    "    tokenizer, lm = load_models(name)\n",
    "    tokenizers.append(tokenizer)\n",
    "    lms.append(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_prob(tokenizer, lm, tokens, query_words):\n",
    "    \"\"\"\n",
    "    tokens: a list of string. One of them is [MASK]\n",
    "    query_words: a list of string. \n",
    "    \"\"\"\n",
    "    encoded = tokenizer.encode(tokens)\n",
    "    mask_pos = tokens.index(\"[MASK]\")\n",
    "    te = torch.tensor([encoded])\n",
    "    output = torch.nn.LogSoftmax(dim=-1)(lm(te)[0])   # (bsz=1, seq, vocab)\n",
    "    probs = output[0, mask_pos].detach()\n",
    "    \n",
    "    query_result = []\n",
    "    for word in query_words:\n",
    "        word_id = tokenizer.encode([word])[0]  # int\n",
    "        log_p_word = probs[word_id].item()\n",
    "        query_result.append((word, log_p_word))\n",
    "    query_result.sort(key=lambda item: item[1])\n",
    "    \n",
    "    return query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('you', -25.962690353393555),\n",
       " ('me', -25.962690353393555),\n",
       " ('something', -25.962690353393555),\n",
       " ('[MASK]', -25.962690353393555)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = \"Hello how are [MASK] ? \".split()\n",
    "query_words = [\"you\", \"me\", \"something\", \"[MASK]\"]\n",
    "qresult = query_prob(tokenizers[-1], lms[-1], tokens, query_words)\n",
    "qresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "    \"The [AGE] [GENDER] with [ATTR] [SPECULATE] [MASK]\": [\"die\", \"recover\"],\n",
    "    \"The [AGE] [GENDER] with [ATTR] [SPECULATE] become [MASK]\": [\"excellent\", \"good\", \"better\", \"ok\", \"worse\", \"bad\"],\n",
    "}\n",
    "\n",
    "age_choices = [\"young\", \"old\"]\n",
    "gender_choices = [\"woman\", \"man\"]\n",
    "#attr_choices = [\"heart disease\", \"hypertension\", \"pneumonia\", \"faint\", \"cold\", \"flu\"]\n",
    "attr_choices = [\"pneumonia\", \"flu\"]\n",
    "speculate_choices = [\"might\", \"could\", \"is likely to\"]\n",
    "\n",
    "\n",
    "def pretty_print_result(result, head=\"\", end=\"\\n\"):\n",
    "    s = head\n",
    "    for item in result:\n",
    "        s = s + f\"{item[0]}: {item[1]:.2f} \"\n",
    "    print (s, end=end)\n",
    "\n",
    "    \n",
    "def batch_process_query():\n",
    "    for template in templates:\n",
    "        print (\"\\nTemplate: \", template)\n",
    "        query_words = templates[template]\n",
    "        \n",
    "        for spec in speculate_choices:\n",
    "            for attr in attr_choices:\n",
    "                for gender in gender_choices:\n",
    "                    for age in age_choices:\n",
    "                        s = template.replace(\"[AGE]\", age)\\\n",
    "                                .replace(\"[GENDER]\", gender)\\\n",
    "                                .replace(\"[ATTR]\", attr)\\\n",
    "                                .replace(\"[SPECULATE]\", spec)\n",
    "                        print (s)\n",
    "                        for i, lm_name in enumerate(lm_names):\n",
    "                            print (\"**\" + lm_name, end=\"\\t\")\n",
    "                            query_result = query_prob(tokenizers[i], lms[i], s.split(), query_words)\n",
    "                            pretty_print_result(query_result, head=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Template:  The [AGE] [GENDER] with [ATTR] [SPECULATE] [MASK]\n",
      "The young woman with pneumonia might [MASK]\n",
      "**bert\t\tdie: -10.77 recover: -10.77 \n",
      "**gpt2\t\tdie: -11.20 recover: -10.55 \n",
      "**clinicalbert\t\tdie: -25.88 recover: -25.88 \n",
      "The old woman with pneumonia might [MASK]\n",
      "**bert\t\tdie: -10.88 recover: -10.88 \n",
      "**gpt2\t\trecover: -10.68 die: -10.56 \n",
      "**clinicalbert\t\tdie: -25.42 recover: -25.42 \n",
      "The young man with pneumonia might [MASK]\n",
      "**bert\t\tdie: -10.60 recover: -10.60 \n",
      "**gpt2\t\tdie: -11.26 recover: -10.05 \n",
      "**clinicalbert\t\tdie: -25.15 recover: -25.15 \n",
      "The old man with pneumonia might [MASK]\n",
      "**bert\t\tdie: -10.79 recover: -10.79 \n",
      "**gpt2\t\trecover: -10.56 die: -10.25 \n",
      "**clinicalbert\t\tdie: -26.16 recover: -26.16 \n",
      "The young woman with flu might [MASK]\n",
      "**bert\t\tdie: -10.25 recover: -10.25 \n",
      "**gpt2\t\tdie: -10.84 recover: -10.73 \n",
      "**clinicalbert\t\tdie: -30.31 recover: -30.31 \n",
      "The old woman with flu might [MASK]\n",
      "**bert\t\tdie: -10.93 recover: -10.93 \n",
      "**gpt2\t\tdie: -10.93 recover: -10.82 \n",
      "**clinicalbert\t\tdie: -29.07 recover: -29.07 \n",
      "The young man with flu might [MASK]\n",
      "**bert\t\tdie: -10.54 recover: -10.54 \n",
      "**gpt2\t\trecover: -11.08 die: -10.64 \n",
      "**clinicalbert\t\tdie: -28.92 recover: -28.92 \n",
      "The old man with flu might [MASK]\n",
      "**bert\t\tdie: -10.42 recover: -10.42 \n",
      "**gpt2\t\trecover: -10.69 die: -9.96 \n",
      "**clinicalbert\t\tdie: -29.19 recover: -29.19 \n",
      "The young woman with pneumonia could [MASK]\n",
      "**bert\t\tdie: -10.11 recover: -10.11 \n",
      "**gpt2\t\tdie: -10.90 recover: -10.65 \n",
      "**clinicalbert\t\tdie: -29.52 recover: -29.52 \n",
      "The old woman with pneumonia could [MASK]\n",
      "**bert\t\tdie: -10.21 recover: -10.21 \n",
      "**gpt2\t\tdie: -10.84 recover: -10.65 \n",
      "**clinicalbert\t\tdie: -29.57 recover: -29.57 \n",
      "The young man with pneumonia could [MASK]\n",
      "**bert\t\tdie: -9.99 recover: -9.99 \n",
      "**gpt2\t\tdie: -11.25 recover: -10.31 \n",
      "**clinicalbert\t\tdie: -29.41 recover: -29.41 \n",
      "The old man with pneumonia could [MASK]\n",
      "**bert\t\tdie: -10.06 recover: -10.06 \n",
      "**gpt2\t\tdie: -10.92 recover: -10.19 \n",
      "**clinicalbert\t\tdie: -31.20 recover: -31.20 \n",
      "The young woman with flu could [MASK]\n",
      "**bert\t\tdie: -10.16 recover: -10.16 \n",
      "**gpt2\t\tdie: -11.81 recover: -10.69 \n",
      "**clinicalbert\t\tdie: -31.94 recover: -31.94 \n",
      "The old woman with flu could [MASK]\n",
      "**bert\t\tdie: -10.39 recover: -10.39 \n",
      "**gpt2\t\tdie: -10.87 recover: -10.43 \n",
      "**clinicalbert\t\tdie: -32.21 recover: -32.21 \n",
      "The young man with flu could [MASK]\n",
      "**bert\t\tdie: -10.12 recover: -10.12 \n",
      "**gpt2\t\tdie: -11.24 recover: -10.78 \n",
      "**clinicalbert\t\tdie: -31.02 recover: -31.02 \n",
      "The old man with flu could [MASK]\n",
      "**bert\t\tdie: -10.63 recover: -10.63 \n",
      "**gpt2\t\tdie: -10.77 recover: -10.24 \n",
      "**clinicalbert\t\tdie: -31.96 recover: -31.96 \n",
      "The young woman with pneumonia is likely to [MASK]\n",
      "**bert\t\tdie: -11.06 recover: -11.06 \n",
      "**gpt2\t\tdie: -11.12 recover: -10.20 \n",
      "**clinicalbert\t\tdie: -26.37 recover: -26.37 \n",
      "The old woman with pneumonia is likely to [MASK]\n",
      "**bert\t\tdie: -10.66 recover: -10.66 \n",
      "**gpt2\t\trecover: -11.24 die: -11.10 \n",
      "**clinicalbert\t\tdie: -27.63 recover: -27.63 \n",
      "The young man with pneumonia is likely to [MASK]\n",
      "**bert\t\tdie: -10.53 recover: -10.53 \n",
      "**gpt2\t\tdie: -11.54 recover: -10.71 \n",
      "**clinicalbert\t\tdie: -26.12 recover: -26.12 \n",
      "The old man with pneumonia is likely to [MASK]\n",
      "**bert\t\tdie: -10.26 recover: -10.26 \n",
      "**gpt2\t\tdie: -11.69 recover: -10.42 \n",
      "**clinicalbert\t\tdie: -27.14 recover: -27.14 \n",
      "The young woman with flu is likely to [MASK]\n",
      "**bert\t\tdie: -10.03 recover: -10.03 \n",
      "**gpt2\t\tdie: -11.70 recover: -10.61 \n",
      "**clinicalbert\t\tdie: -26.46 recover: -26.46 \n",
      "The old woman with flu is likely to [MASK]\n",
      "**bert\t\tdie: -9.96 recover: -9.96 \n",
      "**gpt2\t\tdie: -11.54 recover: -10.20 \n",
      "**clinicalbert\t\tdie: -28.24 recover: -28.24 \n",
      "The young man with flu is likely to [MASK]\n",
      "**bert\t\tdie: -10.12 recover: -10.12 \n",
      "**gpt2\t\trecover: -11.27 die: -11.05 \n",
      "**clinicalbert\t\tdie: -26.22 recover: -26.22 \n",
      "The old man with flu is likely to [MASK]\n",
      "**bert\t\tdie: -10.56 recover: -10.56 \n",
      "**gpt2\t\tdie: -11.27 recover: -10.93 \n",
      "**clinicalbert\t\tdie: -27.74 recover: -27.74 \n",
      "\n",
      "Template:  The [AGE] [GENDER] with [ATTR] [SPECULATE] become [MASK]\n",
      "The young woman with pneumonia might become [MASK]\n",
      "**bert\t\texcellent: -9.94 good: -9.94 better: -9.94 ok: -9.94 worse: -9.94 bad: -9.94 \n",
      "**gpt2\t\tok: -11.19 good: -11.13 bad: -10.78 excellent: -10.78 worse: -10.78 better: -10.43 \n",
      "**clinicalbert\t\texcellent: -24.86 good: -24.86 better: -24.86 ok: -24.86 worse: -24.86 bad: -24.86 \n",
      "The old woman with pneumonia might become [MASK]\n",
      "**bert\t\texcellent: -10.66 good: -10.66 better: -10.66 ok: -10.66 worse: -10.66 bad: -10.66 \n",
      "**gpt2\t\tgood: -11.22 excellent: -11.01 worse: -11.01 ok: -10.96 better: -10.60 bad: -10.45 \n",
      "**clinicalbert\t\texcellent: -25.43 good: -25.43 better: -25.43 ok: -25.43 worse: -25.43 bad: -25.43 \n",
      "The young man with pneumonia might become [MASK]\n",
      "**bert\t\texcellent: -9.84 good: -9.84 better: -9.84 ok: -9.84 worse: -9.84 bad: -9.84 \n",
      "**gpt2\t\tgood: -11.97 better: -10.98 ok: -10.76 excellent: -10.60 worse: -10.60 bad: -10.27 \n",
      "**clinicalbert\t\texcellent: -25.27 good: -25.27 better: -25.27 ok: -25.27 worse: -25.27 bad: -25.27 \n",
      "The old man with pneumonia might become [MASK]\n",
      "**bert\t\texcellent: -9.61 good: -9.61 better: -9.61 ok: -9.61 worse: -9.61 bad: -9.61 \n",
      "**gpt2\t\tgood: -11.34 bad: -11.10 ok: -10.58 excellent: -10.22 worse: -10.22 better: -9.80 \n",
      "**clinicalbert\t\texcellent: -26.12 good: -26.12 better: -26.12 ok: -26.12 worse: -26.12 bad: -26.12 \n",
      "The young woman with flu might become [MASK]\n",
      "**bert\t\texcellent: -10.13 good: -10.13 better: -10.13 ok: -10.13 worse: -10.13 bad: -10.13 \n",
      "**gpt2\t\texcellent: -11.09 worse: -11.09 good: -10.91 bad: -10.64 ok: -10.56 better: -9.97 \n",
      "**clinicalbert\t\texcellent: -26.70 good: -26.70 better: -26.70 ok: -26.70 worse: -26.70 bad: -26.70 \n",
      "The old woman with flu might become [MASK]\n",
      "**bert\t\texcellent: -10.34 good: -10.34 better: -10.34 ok: -10.34 worse: -10.34 bad: -10.34 \n",
      "**gpt2\t\tgood: -10.83 excellent: -10.54 worse: -10.54 better: -10.49 ok: -10.42 bad: -9.98 \n",
      "**clinicalbert\t\texcellent: -26.79 good: -26.79 better: -26.79 ok: -26.79 worse: -26.79 bad: -26.79 \n",
      "The young man with flu might become [MASK]\n",
      "**bert\t\texcellent: -10.26 good: -10.26 better: -10.26 ok: -10.26 worse: -10.26 bad: -10.26 \n",
      "**gpt2\t\tbad: -11.07 good: -11.01 excellent: -10.69 worse: -10.69 ok: -10.67 better: -9.89 \n",
      "**clinicalbert\t\texcellent: -27.05 good: -27.05 better: -27.05 ok: -27.05 worse: -27.05 bad: -27.05 \n",
      "The old man with flu might become [MASK]\n",
      "**bert\t\texcellent: -10.27 good: -10.27 better: -10.27 ok: -10.27 worse: -10.27 bad: -10.27 \n",
      "**gpt2\t\tbetter: -11.10 bad: -11.06 good: -10.77 excellent: -10.61 worse: -10.61 ok: -10.48 \n",
      "**clinicalbert\t\texcellent: -27.32 good: -27.32 better: -27.32 ok: -27.32 worse: -27.32 bad: -27.32 \n",
      "The young woman with pneumonia could become [MASK]\n",
      "**bert\t\texcellent: -9.97 good: -9.97 better: -9.97 ok: -9.97 worse: -9.97 bad: -9.97 \n",
      "**gpt2\t\texcellent: -11.01 worse: -11.01 better: -11.01 good: -11.00 bad: -10.66 ok: -10.14 \n",
      "**clinicalbert\t\texcellent: -23.93 good: -23.93 better: -23.93 ok: -23.93 worse: -23.93 bad: -23.93 \n",
      "The old woman with pneumonia could become [MASK]\n",
      "**bert\t\texcellent: -10.22 good: -10.22 better: -10.22 ok: -10.22 worse: -10.22 bad: -10.22 \n",
      "**gpt2\t\tgood: -11.68 excellent: -10.51 worse: -10.51 ok: -10.47 better: -10.32 bad: -10.08 \n",
      "**clinicalbert\t\texcellent: -24.34 good: -24.34 better: -24.34 ok: -24.34 worse: -24.34 bad: -24.34 \n",
      "The young man with pneumonia could become [MASK]\n",
      "**bert\t\texcellent: -10.74 good: -10.74 better: -10.74 ok: -10.74 worse: -10.74 bad: -10.74 \n",
      "**gpt2\t\tgood: -11.58 better: -10.76 bad: -10.74 ok: -10.62 excellent: -10.49 worse: -10.49 \n",
      "**clinicalbert\t\texcellent: -23.92 good: -23.92 better: -23.92 ok: -23.92 worse: -23.92 bad: -23.92 \n",
      "The old man with pneumonia could become [MASK]\n",
      "**bert\t\texcellent: -10.54 good: -10.54 better: -10.54 ok: -10.54 worse: -10.54 bad: -10.54 \n",
      "**gpt2\t\tgood: -11.16 ok: -10.76 better: -10.40 bad: -10.36 excellent: -9.96 worse: -9.96 \n",
      "**clinicalbert\t\texcellent: -24.75 good: -24.75 better: -24.75 ok: -24.75 worse: -24.75 bad: -24.75 \n",
      "The young woman with flu could become [MASK]\n",
      "**bert\t\texcellent: -10.31 good: -10.31 better: -10.31 ok: -10.31 worse: -10.31 bad: -10.31 \n",
      "**gpt2\t\tgood: -11.44 bad: -10.95 ok: -10.64 excellent: -10.19 worse: -10.19 better: -9.92 \n",
      "**clinicalbert\t\texcellent: -25.00 good: -25.00 better: -25.00 ok: -25.00 worse: -25.00 bad: -25.00 \n",
      "The old woman with flu could become [MASK]\n",
      "**bert\t\texcellent: -10.34 good: -10.34 better: -10.34 ok: -10.34 worse: -10.34 bad: -10.34 \n",
      "**gpt2\t\tbad: -10.76 good: -10.73 ok: -10.57 excellent: -10.55 worse: -10.55 better: -10.19 \n",
      "**clinicalbert\t\texcellent: -25.12 good: -25.12 better: -25.12 ok: -25.12 worse: -25.12 bad: -25.12 \n",
      "The young man with flu could become [MASK]\n",
      "**bert\t\texcellent: -10.33 good: -10.33 better: -10.33 ok: -10.33 worse: -10.33 bad: -10.33 \n",
      "**gpt2\t\tgood: -11.18 ok: -10.52 excellent: -10.52 worse: -10.52 better: -10.32 bad: -9.96 \n",
      "**clinicalbert\t\texcellent: -24.67 good: -24.67 better: -24.67 ok: -24.67 worse: -24.67 bad: -24.67 \n",
      "The old man with flu could become [MASK]\n",
      "**bert\t\texcellent: -9.87 good: -9.87 better: -9.87 ok: -9.87 worse: -9.87 bad: -9.87 \n",
      "**gpt2\t\tgood: -11.69 excellent: -10.95 worse: -10.95 ok: -10.44 bad: -10.32 better: -10.14 \n",
      "**clinicalbert\t\texcellent: -25.09 good: -25.09 better: -25.09 ok: -25.09 worse: -25.09 bad: -25.09 \n",
      "The young woman with pneumonia is likely to become [MASK]\n",
      "**bert\t\texcellent: -10.30 good: -10.30 better: -10.30 ok: -10.30 worse: -10.30 bad: -10.30 \n",
      "**gpt2\t\tgood: -11.51 bad: -10.67 better: -10.56 excellent: -10.53 worse: -10.53 ok: -9.46 \n",
      "**clinicalbert\t\texcellent: -24.66 good: -24.66 better: -24.66 ok: -24.66 worse: -24.66 bad: -24.66 \n",
      "The old woman with pneumonia is likely to become [MASK]\n",
      "**bert\t\texcellent: -10.45 good: -10.45 better: -10.45 ok: -10.45 worse: -10.45 bad: -10.45 \n",
      "**gpt2\t\tgood: -11.64 excellent: -10.89 worse: -10.89 bad: -10.89 ok: -10.54 better: -10.25 \n",
      "**clinicalbert\t\texcellent: -24.83 good: -24.83 better: -24.83 ok: -24.83 worse: -24.83 bad: -24.83 \n",
      "The young man with pneumonia is likely to become [MASK]\n",
      "**bert\t\texcellent: -10.09 good: -10.09 better: -10.09 ok: -10.09 worse: -10.09 bad: -10.09 \n",
      "**gpt2\t\tgood: -11.91 better: -11.05 bad: -10.69 excellent: -10.37 worse: -10.37 ok: -9.64 \n",
      "**clinicalbert\t\texcellent: -24.76 good: -24.76 better: -24.76 ok: -24.76 worse: -24.76 bad: -24.76 \n",
      "The old man with pneumonia is likely to become [MASK]\n",
      "**bert\t\texcellent: -10.60 good: -10.60 better: -10.60 ok: -10.60 worse: -10.60 bad: -10.60 \n",
      "**gpt2\t\tgood: -11.19 bad: -10.72 better: -10.62 excellent: -10.42 worse: -10.42 ok: -10.22 \n",
      "**clinicalbert\t\texcellent: -24.95 good: -24.95 better: -24.95 ok: -24.95 worse: -24.95 bad: -24.95 \n",
      "The young woman with flu is likely to become [MASK]\n",
      "**bert\t\texcellent: -10.83 good: -10.83 better: -10.83 ok: -10.83 worse: -10.83 bad: -10.83 \n",
      "**gpt2\t\tgood: -12.01 excellent: -11.55 worse: -11.55 bad: -10.96 better: -10.60 ok: -9.80 \n",
      "**clinicalbert\t\texcellent: -25.74 good: -25.74 better: -25.74 ok: -25.74 worse: -25.74 bad: -25.74 \n",
      "The old woman with flu is likely to become [MASK]\n",
      "**bert\t\texcellent: -10.20 good: -10.20 better: -10.20 ok: -10.20 worse: -10.20 bad: -10.20 \n",
      "**gpt2\t\tgood: -11.49 bad: -10.73 excellent: -10.64 worse: -10.64 better: -10.22 ok: -10.20 \n",
      "**clinicalbert\t\texcellent: -25.53 good: -25.53 better: -25.53 ok: -25.53 worse: -25.53 bad: -25.53 \n",
      "The young man with flu is likely to become [MASK]\n",
      "**bert\t\texcellent: -10.47 good: -10.47 better: -10.47 ok: -10.47 worse: -10.47 bad: -10.47 \n",
      "**gpt2\t\tgood: -11.93 excellent: -11.22 worse: -11.22 better: -10.69 ok: -10.47 bad: -10.25 \n",
      "**clinicalbert\t\texcellent: -25.91 good: -25.91 better: -25.91 ok: -25.91 worse: -25.91 bad: -25.91 \n",
      "The old man with flu is likely to become [MASK]\n",
      "**bert\t\texcellent: -10.44 good: -10.44 better: -10.44 ok: -10.44 worse: -10.44 bad: -10.44 \n",
      "**gpt2\t\tbad: -11.21 good: -11.14 better: -10.44 ok: -10.39 excellent: -10.27 worse: -10.27 \n",
      "**clinicalbert\t\texcellent: -25.64 good: -25.64 better: -25.64 ok: -25.64 worse: -25.64 bad: -25.64 \n"
     ]
    }
   ],
   "source": [
    "batch_process_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
